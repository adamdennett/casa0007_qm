---
title: "Introduction to Applied Linear Regression"
subtitle: "One model to rule them all!"
author: 
  - name: "Adam Dennett"
email: "a.dennett@ucl.ac.uk"
date-as-string: "1st August 2024"
other: "CASA0007 Quantitative Methods"
from: markdown+emoji
format:
  revealjs: 
    logo: "images/CASA_logo.svg"
    template-partials: 
      - title-slide.html
    transition: none
    slide-number: TRUE
    preview-links: auto
    theme: casa-slides.scss
    
filters:
 - code-visibility
lightbox: auto
title-slide-attributes:
    data-background-image: "images/title-slide.png"
    data-background-size: stretch
    data-background-opacity: "0.08"
    data-background-color: "#4e3c56"
---

```{r}
#| label: load-data
#| message: false
#| warning: false
#| include: false

#casaviz::view_palette(casaviz::casa_palettes$default, n_colours = 10)

##before we do anything else, let's load the packages we need and the data we require

library(casaviz)
library(tidyverse)
library(sf)
library(plotly)
library(leaflet)
library(rgl)
library(dplyr)
library(here)
library(stringr)
library(dplyr)
library(purrr)
library(janitor)
library(readxl)
library(tibble)
library(ggrepel)
library(gganimate)

#all england schools
edubase_schools <- read_csv("https://www.dropbox.com/scl/fi/fhzafgt27v30lmmuo084y/edubasealldata20241003.csv?rlkey=uorw43s44hnw5k9js3z0ksuuq&raw=1") %>% 
  clean_names() %>% 
  mutate(urn = as.character(urn))

england_abs <- read_csv(here("wk6", "data", "Performancetables_130242", "2022-2023", "england_abs.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>%
  mutate(URN = as.character(URN))
england_census <- read_csv(here("wk6", "data", "Performancetables_130242", "2022-2023", "england_census.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>%
  mutate(URN = as.character(URN)) %>%
  mutate(across(5:23, ~ parse_number(as.character(.))))
england_ks4_mats_performance <- read_csv(
  here("wk6", "data", "Performancetables_130242", "2022-2023", "england_ks4-mats-performance.csv"),
  na = c("", "NA", "SUPPMAT", "NP", "NE")
) %>%
  mutate(
    TRUST_UID = as.character(TRUST_UID),
    P8_BANDING = as.character(P8_BANDING),
    INSTITUTIONS_INMAT = as.character(INSTITUTIONS_INMAT)
  ) %>%
  mutate(across(
    .cols = names(.)[11:ncol(.)][!names(.)[11:ncol(.)] %in% c("P8_BANDING", "INSTITUTIONS_INMAT")],
    .fns = ~ parse_number(as.character(.))
  ))

england_ks4_pupdest <- read_csv(here("wk6", "data", "Performancetables_130242", "2022-2023", "england_ks4-pupdest.csv"), na = c("", "NA", "SUPP", "NP", "NE", "SP", "SN")) %>%
  mutate(URN = as.character(URN)) %>%
  mutate(across(8:82, ~ parse_number(as.character(.))))

england_ks4final <- read_csv(here("wk6", "data", "Performancetables_130242", "2022-2023", "england_ks4final.csv"), na = c("", "NA", "SUPP", "NP", "NE", "SP", "LOWCOV", "NEW")) %>%
  mutate(URN = as.character(URN)) %>%
  mutate(across(TOTPUPS:PTOTENT_E_COVID_IMPACTED_PTQ_EE, ~ parse_number(as.character(.))))

england_school_information <- read_csv(
  here("wk6", "data", "Performancetables_130242", "2022-2023", "england_school_information.csv"),
  na = c("", "NA", "SUPP", "NP", "NE", "SP"),
  col_types = cols(
    URN = col_character(),
    OFSTEDLASTINSP = col_date(format = "%d-%m-%Y")  # Adjust format if needed
  )
)


abs_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "abs_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
census_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "census_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
ks4_mats_performance_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "ks4-mats-performance_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
ks4_pupdest_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "ks4-pupdest_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
ks4final_meta <- read_xlsx(here("wk6","data", "Performancetables_130249", "2022-2023", "ks4_meta.xlsx"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
school_information_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "la_and_region_codes_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
la_and_region_codes_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "la_and_region_codes_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()
school_information_meta <- read_csv(here("wk6","data", "Performancetables_130249", "2022-2023", "school_information_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()

# str(england_abs)
# str(england_census)
# str(england_ks4_mats_performance)
# str(england_ks4_pupdest)
# str(england_ks4final)
# str(england_school_information)
# str(abs_meta)
# str(census_meta)
# str(ks4_mats_performance_meta)
# str(ks4_pupdest_meta)
# str(ks4final_meta)
# str(school_information_meta)
# str(la_and_region_codes_meta)


```

```{r}

# Custom join function to drop duplicate columns (except URN)
# safe_left_join <- function(x, y) {
#   common_cols <- intersect(names(x), names(y))
#   common_cols <- setdiff(common_cols, "URN")  # keep URN
#   y_clean <- y |> select(-all_of(common_cols))
#   left_join(x, y_clean, by = "URN")
# }

# Perform sequential joins
# england_school_2022_23 <- safe_left_join(england_ks4final) |>
#   safe_left_join(england_abs) |>
#   safe_left_join(england_census) |>
#   safe_left_join(england_ks4_pupdest) |>
#   safe_left_join(england_school_information)

# Left join england_ks4final with england_abs
england_school_2022_23 <- england_ks4final %>%
  left_join(england_abs, by = "URN") %>%
  left_join(england_census, by = "URN") %>%
  left_join(england_school_information, by = "URN")

# Filter out special schools and those with ADMPOL (admissions policy) = "NSE" (non-selective)

england_school_2022_23 <- england_school_2022_23 |>
  left_join(edubase_schools, by = c("URN" = "urn"))

england_school_2022_23_not_special <- england_school_2022_23 %>%
  filter(MINORGROUP != "Special school")

#column_headers_df <- tibble(column_name = names(england_school_2022_23))
  
```

## This week's Session {transition="convex-in none-out" transition-speed="fast"}

```{r, echo=FALSE}
# This makes the fonts play nicely within the figures
knitr::opts_chunk$set(dev = "ragg_png")

```

```{css}
/* This sits here, because it allows us to use images from within the images/ folder. Otherwise, the file structure gets a lot more involved! */
.reveal::after {
  background-image: url('images/light-background.png');
}
```

By the end of this session, we will understand:

-   linear Regression and why it is perhaps *THE* most useful tool in your statistical toolbox - but only if used correctly
-   how correct use depends mainly on:
    -   understanding the features of your data - sample size, the variables and groups within your data, multicolinearity, heteroscedascity, kurtosis, variance, degrees of freedom, interaction effects (and what all of these words mean!)
    -   how a model and the variables you put into that model should always be informed by a sound theoretical understanding

## This week's Session {transition="convex-in none-out" transition-speed="fast"}

-   a fool-proof recipe for any future modelling exercise you undertake, including:
    -   the fundamental importance of visualising your data and the relationships you are trying to fit a model to
    -   how to interpret the outputs from your model and how they relate back to the visual patterns you observe and the rules that govern the model
-   an example of how poor urban policy can be based a misunderstanding of data, models and local context, but how the same models, if used correctly, can also underpin better policy

# Our Case Study - What are the Factors Affecting School-Level Educational Attainment in Brighton and Hove? {background-image="https://adamdennett.github.io/BH_Schools_Consultation/attainment_extra_files/figure-html/unnamed-chunk-10-1.png" background="#2e6260" background-opacity="0.1"}

## Secondary Schools and Attainment - GCSEs {transition="convex-in none-out" transition-speed="fast"}

-   Secondary Schools mainly teach children between the ages of 11-16 in England and Wales (some 11-18, some 13-18)
-   The examinations most children take at the end of Year 11 (age 16) are called GCSEs (General Certificate of Secondary Education)
-   The GCSEs are graded from 9 (highest) to 1 (lowest), with a grade of 4 considered a "standard pass" and a grade of 5 considered a "strong pass"

## Secondary Schools and Attainment - Attainment 8 {transition="convex-in none-out" transition-speed="fast"}

-   Attainment 8 is a measure that sums the grades for each pupil across 8 GCSEs (the standard number taken).
    -   Maths is always counted twice and English often counted twice where both language and literature are taken.
    -   Thus a maximum Attainment 8 score of 90 can be achieved
    -   40 = Standard Pass, 50 = Strong Pass
-   The Attainment 8 scores for all year 11 students can be averaged for each school giving a school-level average Attainment 8 Score
-   Attainment 8 is a raw score and doesn't account for important variations in the cohorts of students each school admits or the types of school, so direct comparison between schools without accounting for these factors is risky

## Secondary Schools and Attainment - Progress 8 {transition="convex-in none-out" transition-speed="fast"}

-   Progress 8 is an alternative attainment score which looks at the progress a student makes between arriving at a school in year 7 or 9 and leaving at age 16
-   It compares their levels of attainment at entry and exit with the progress made by similar students nationally
-   Progress 8 is a 'value-added' ratio. A score of zero means students, on average, made expected progress, while a positive score means they made more progress than expected, and a negative score means they made less

## Secondary Schools, Attainment and Urban Policy {transition="convex-in none-out" transition-speed="fast"}

::::: columns
::: {.column width="60%"}
-   School performance and pupil attainment can be a big urban policy issue - particularly where variations in access and perceived quality occur
-   These variations feed into broader socio-economic issues in cities
-   In the UK, schools are the responsibility of local government
-   Understanding the drivers behind pupil attainment and school performance vital for effective resource allocation and good local policy
:::

::: {.column width="40%"}
![](images/BHCC_Engagement_PPT.png)
:::
:::::

::: footer
:::

## Secondary Schools, Attainment and Urban Policy {transition="convex-in none-out" transition-speed="fast"}

::::: columns
::: {.column width="60%"}
-   In 2024, Brighton and Hove Council convinced that the biggest driver of pupil attainment within schools was social mixing
-   The 'disadvantage attainment gap' - socio-economically disadvantaged students tend to perform worse than their more affluent peers
-   Belief based, primarily, on work of Professor Stephen Gorard, University of Durham
-   Solution: create more socially mixed schools through a new controversial admissions policy
:::

::: {.column width="40%"}
![](images/gorard_conversation.png)
:::
:::::

::: footer
The Conversation: <https://theconversation.com/poorer-pupils-do-worse-at-school-heres-how-to-reduce-the-attainment-gap-205535>
:::

## Reserarch Question(s) {transition="convex-in none-out" transition-speed="fast"}

-   What are the factors that affect school-level educational attainment in Brighton and Hove?
-   To what extent is attainment driven by social mixing?
-   Are there any other factors that are relevant?
-   What are the implications of this for local policy?
-   Can regression help us and, if it can, how can we go about carefully building a regression model to help us answer these questions?

# A Reliable Regression Modelling Recipe {background-image="https://adamdennett.github.io/BH_Schools_Consultation/attainment_extra_files/figure-html/unnamed-chunk-10-1.png" background="#2e6260" background-opacity="0.1"}

## Recipe / Framework {transition="convex-in none-out" transition-speed="fast"}

::::: columns
::: {.column width="60%"}
-   One way to think about regression modelling is as a recipe.
-   The recipe has a number of steps, each of which is important to the final outcome
-   As with baking a cake, failure will follow if you don't:
    -   get your ingredients right
    -   follow the method correctly
    -   use your equipment in the right way
-   You may need to iterate around these a few times during the process
:::

::: {.column width="40%"}
![](https://gu-witness.s3.amazonaws.com/media/31ab0d58-3f7a-44d0-842e-adfcf80f1d8c-mediumoriginalaspectdouble.jpg)
:::
:::::

::: footer
:::

## Step 1 - Ingredients {transition="convex-in none-out" transition-speed="fast"}

-   The Exploratory Data Analysis (EDA) phase is the most important part of any modelling exercise (see Weeks 1 & 2 of this course)
-   It is where you get to know your data (ingredients) - the variables, data types, distributions, any spatial or temporal patterns
-   Failure to get to know your data properly means you might mis-specify your model by:
    -   using the wrong explanatory variables or omitting some key ones
    -   misunderstanding your data types - e.g. counts vs continuous
    -   misunderstanding the relationships between your variables (linear vs logarithmic)
    -   not accounting for important spatial or temporal patterns (autocorrelation) that might mean your observations are not independent

## Step 1a - Ingredients (gathering and preparation) {transition="convex-in none-out" transition-speed="fast"}

::::: columns
::: {.column width="60%"}
-   The data is collected by the Department for Education (DfE), published annually and is comprehensive - a full annual census of each school
-   For each school, hundreds of variables are available relating to:
    -   attainment and progress
    -   pupil characteristics
    -   school characteristics
-   Some data / variables (ingredients) will be more useful than others
:::

::: {.column width="40%"}
![](images/gov_school_data.png)
:::
:::::

::: footer
DfE Data: <https://www.compare-school-performance.service.gov.uk/compare-schools>
:::

## Step 1a - Ingredients (gathering and preparation) {transition="convex-in none-out" transition-speed="fast"}

```{r}
library(reactable)
library(casaviz)  # assuming casa_reactable_theme is defined here

england_school_2022_23 %>% 
  filter(LANAME == "Brighton and Hove") %>% 
  filter(phase_of_education_name == "Secondary") %>% 
  filter(establishment_status_name == "Open") %>% 
  select(URN, SCHNAME.x, TOWN.x, TOTPUPS, ATT8SCR, OFSTEDRATING, MINORGROUP, PTFSM6CLA1A) |>
  reactable(theme = casa_reactable_theme(colour = "purple"))
```

## Step 1b - Ingredients (familiarisation) {transition="convex-in none-out" transition-speed="fast"}

```{r}
library(dplyr)

filtered_df <- england_school_2022_23 %>%
  filter(LANAME == "Brighton and Hove",
         phase_of_education_name == "Secondary",
         establishment_status_name == "Open") %>%
  select(URN, SCHNAME.x, TOWN.x, TOTPUPS, ATT8SCR, OFSTEDRATING, MINORGROUP, PTFSM6CLA1A, easting, northing)

library(sf)

# Convert to sf object with EPSG:27700
sf_df <- st_as_sf(filtered_df, coords = c("easting", "northing"), crs = 27700)

# Transform to EPSG:4326
sf_df <- st_transform(sf_df, crs = 4326)

# Extract lat/lon for leaflet
sf_df <- sf_df %>%
  mutate(
    lon = st_coordinates(.)[,1],
    lat = st_coordinates(.)[,2]
  )

library(leaflet)
library(scales)

# Define size and color scales
size_scale <- rescale(sf_df$TOTPUPS, to = c(4, 12))  # radius from 4 to 12
# Create custom color palette
casa_palette <- casa_palettes$default
color_scale <- colorNumeric(palette = casa_palette, domain = sf_df$TOTPUPS)


leaflet(sf_df) |>
  addProviderTiles("CartoDB.Positron") |>  # plain, minimal basemap
  addCircleMarkers(
    lng = ~lon,
    lat = ~lat,
    radius = size_scale,
    color = ~color_scale(TOTPUPS),
    stroke = FALSE,
    fillOpacity = 0.8,
    popup = ~paste0(
      "<strong>", SCHNAME.x, "</strong><br>",
      "Pupils: ", TOTPUPS
    )
  ) |> 
  addLegend(
    "bottomright",
    pal = color_scale,
    values = ~TOTPUPS,
    title = "Total Pupils",
    opacity = 0.7
  )
```

-   Visualisation is perhaps the most important part of the EDA phase
-   Always map and graph your data so that you can spot potential issues before they ruin your model!

## Step 1b - Ingredients (familiarisation) {transition="convex-in none-out" transition-speed="fast"}

```{r}
#| label: attainment-8-histogram
#| fig.width: 8
#| fig.height: 5
#| fig.align: "center"

median_value <- median(england_school_2022_23$ATT8SCR, na.rm = TRUE)
mean_value   <- mean(england_school_2022_23$ATT8SCR, na.rm = TRUE)
sd_value   <- sd(england_school_2022_23$ATT8SCR, na.rm = TRUE)

ggplot(england_school_2022_23, aes(x = ATT8SCR)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#4E3C56", alpha = 0.4) +
  stat_function(fun = dnorm, args = list(mean = mean_value, sd = sd_value),
                color = "#2E6260", size = 1) +
  geom_vline(xintercept = median_value, color = "black", linetype = "dotted", size = 1) +
  geom_vline(xintercept = mean_value, color = "#F9DD73", linetype = "solid", size = 1) +
  annotate("text",
           x = median_value, y = Inf,
           label = paste0("Median = ", round(median_value, 1)),
           vjust = 1.3, color = "black", size = 3.5) +
  annotate("text",
           x = mean_value, y = Inf,
           label = paste0("Mean = ", round(mean_value, 1)),
           vjust = 30.5, color = "#F9DD73", size = 3.5) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.08))) +
  labs(
    title = "Attainment 8 - All Schools England and Wales, 2022/23 Academic Year",
    x = "Attainment 8 Score",
    y = "Density"
  ) +
  theme_minimal()


```

-  Hmmm? Are there any problems that could be indicated here?

## Step 1b - Ingredients (familiarisation) {transition="convex-in none-out" transition-speed="fast"}

```{r}
#| label: attainment-8-boxplot
#| fig.width: 8
#| fig.height: 5
#| fig.align: "center"

library(ggplot2)
library(casaviz)  # ensure the package is loaded so its scale functions are available

median_value <- median(england_school_2022_23$ATT8SCR, na.rm = TRUE)

ggplot(england_school_2022_23, aes(x = ATT8SCR, y = "")) +
  geom_boxplot(fill = "#EDD971", alpha = 0.1, outlier.shape = NA) +    
  geom_jitter(aes(colour = MINORGROUP), height = 0.2, alpha = 0.8, size = 1) + 
  scale_colour_casa() +  # applies the default casaviz discrete palette
  labs(
    title = "Attainment 8 - All Schools 2022/23 Academic Year",
    x = "Attainment 8 Score",
    y = NULL,
    colour = "School Type"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.key.size = unit(10, "mm"),   # increase dot space
    legend.text = element_text(size = 10)  # optional: larger legend labels
  ) + guides(colour = guide_legend(override.aes = list(size = 4)))
```

-   Notice anything now?
-   What could/should we do about it? Any suggestions?

## Step 1c - Ingredients (selection) {transition="convex-in none-out" transition-speed="fast"}

```{r}
library(ggplot2)
library(dplyr)

# Filter out unwanted categories
england_filtered <- england_school_2022_23 %>%
  filter(!MINORGROUP %in% c("Special school", "Independent school", "College", NA))

# Recalculate stats on the filtered data
median_value <- median(england_filtered$ATT8SCR, na.rm = TRUE)
mean_value   <- mean(england_filtered$ATT8SCR, na.rm = TRUE)

ggplot(england_filtered, aes(x = ATT8SCR, y = "")) +
  geom_boxplot(fill = "#EDD971", alpha = 0.1, outlier.shape = NA) +    
  geom_jitter(aes(colour = MINORGROUP), height = 0.2, alpha = 0.5, size = 1) + 
  # Median + mean lines
  # Custom fixed palette matching previous graph
  scale_colour_manual(
    values = c(
      "Academy"          = "#2E6260",
      "Maintained school" = "#E16FCA"
    )
  ) +
  labs(
    title = "Attainment 8 - Academy and Maintained Schools 2022/23 Academic Year",
    x = "Attainment 8 Score",
    y = NULL,
    colour = "School Type"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.key.size = unit(4, "mm")
  ) +
  guides(colour = guide_legend(override.aes = list(size = 3)))
```

## Step 1c - Ingredients (selection) {transition="convex-in none-out" transition-speed="fast"}

```{r}
#| label: attainment-8-histogram2
#| fig.width: 8
#| fig.height: 5
#| fig.align: "center"

library(ggplot2)
library(dplyr)

# Filter data
england_filtered <- england_school_2022_23 %>%
  filter(!MINORGROUP %in% c("Special school", "Independent school", "College", NA))

# Recalculate stats for filtered data
median_value <- median(england_filtered$ATT8SCR, na.rm = TRUE)
mean_value   <- mean(england_filtered$ATT8SCR, na.rm = TRUE)
sd_value   <- sd(england_filtered$ATT8SCR, na.rm = TRUE)

ggplot(england_filtered, aes(x = ATT8SCR)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#4E3C56", alpha = 0.4) +
  stat_function(fun = dnorm, args = list(mean = mean_value, sd = sd_value),
                color = "#2E6260", size = 1) +
  geom_vline(xintercept = median_value, colour = "black", linetype = "dotted", size = 1) +
  geom_vline(xintercept = mean_value, colour = "#F9DD73", linetype = "solid", size = 1) +
  annotate("text",
           x = median_value, y = Inf,
           label = paste0("Median = ", round(median_value, 1)),
           vjust = 1.3, colour = "black", size = 3.5) +
  annotate("text",
           x = mean_value, y = Inf,
           label = paste0("Mean = ", round(mean_value, 1)),
           vjust = 30.5, colour = "#F9DD73", size = 3.5) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.08))) +
  labs(
    title = "Attainment 8 - Academy and Maintained Schools 2022/23 Academic Year",
    x = "Attainment 8 Score",
    y = "Density"
  ) +
  theme_minimal()
```

## Step 1c - Ingredients (selection) {transition="convex-in none-out" transition-speed="fast"}

-   The process of exploring and interrogating your data should take much longer than the modelling at the end
-   The process is iterative - you might well be exploring your data and the theory ***at the same time*** to help you explore, filter, select and prepare for the modelling phase
-   Understanding your 'system' and what the key elements are is vital.
    -   Sometimes this might come from experience (e.g. I used to be a school teacher so know that 'Special Schools' teach children with complex needs where academic performance is likely to be lower or that if you are at 'college' \[usually post-16\], then likely to be re-taking or studying for a reduced programme of GCSEs))
    -   more often you will have to carry out your own research to help you understand your system and its key elements

## Step 1c - Ingredients (selection) {transition="convex-in none-out" transition-speed="fast"}

-   The role of theory and wider research on your system is vital in helping you select your variables for investigation
-   **DO NOT JUST THROW EVERYTHING INTO YOUR MODEL JUST BECAUSE YOU HAVE SOME VARIABLES**
    -   This is a common mistake
    -   It can also lead to spurious interpretation where correlation and causation are not the same thing
-   Carrying out a thorough literature review will also give you context for interpreting your model results later on in the process

## Step 1c - Ingredients (selection) {transition="convex-in none-out" transition-speed="fast"}

::::: columns
::: {.column width="60%"}
-   Brighton and Hove City Council relied heavily on the work of Gorard in building its policy
-   Paper links social mixing to improved attainment for disadvantaged pupils
-   Includes variables such as:
    -   school type (e.g. academy, maintained)
    -   pupil characteristics (e.g. free school meals (FSM) eligibility, special educational needs, ethnicity)
    -   school characteristics (e.g. size, location)
-   Thus all might be worth investigating
:::

::: {.column width="40%"}
![](images/gorard_disad_paper.png)
:::
:::::

::: footer
<https://journals.sagepub.com/doi/full/10.1177/2158244018825171>
:::

## Step 1c - Ingredients (selection) {transition="convex-in none-out" transition-speed="fast"}

::::: columns
::: {.column width="60%"}
-   However, wider reading also suggests that factors such as attendance (which Gordard does not include in his paper as a variable) may also play a big role in the attainment of disadvantaged pupils
-   Work by Claymore suggests that a large proportion of the gap in attainment between disadvantaged pupils and more affluent peers can be explained by:
    -   the differences in absence rates
    -   exclusion
    -   rates of moving between schools
:::

::: {.column width="40%"}
![](images/nfer.png)
:::
:::::

::: footer
<https://www.nfer.ac.uk/publications/being-present-the-power-of-attendance-and-stability-for-disadvantaged-pupils/>
:::

## Step 2 - Method

![](images/stat_tests.png){width="80%"}

::: Footer
<https://statsandr.com/blog/files/overview-statistical-tests-statsandr.pdf>
:::

## Step 2 - Method {transition="convex-in none-out" transition-speed="fast"}

-   ***Based on our raw ingredients, which methods might allow us to try and answer our research question(s)?***
-   ***Dependent variable(s)*** (what we are trying to explain / predict): Attainment 8 / Progress 8 **-\>** continuous / Ratio scales
-   ***Independent variables*** - explanatory / predictor variables of varying data types to explain variation in the dependent variable
-   As such ***Linear Regression*** is the most appropriate statistical test to employ



## Linear Regression - It's just a scatter plot!


```{r}
#| warning: FALSE
#| out-width: "60%"
#| fig-align: "center"

## get LEA Code from here: https://get-information-schools.service.gov.uk/Guidance/LaNameCodes

# Filter data
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

#| warning: FALSE
#| out-width: "60%"
#| fig-align: "center"

## get LEA Code from here: https://get-information-schools.service.gov.uk/Guidance/LaNameCodes

# Filter data
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Define custom color palette
custom_colors <- c(
  "#2E6260", "#658E62", "#9DBB65", "#C4CE6A", "#E7D870",
  "#F3C486", "#E993AC", "#D069BD", "#8F5289", "#4E3C56"
)

school_levels <- unique(btn_sub$SCHNAME.x)
school_colors <- setNames(
  rep(custom_colors, length.out = length(school_levels)),
  school_levels
)


# Filter data
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>%
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Fit linear model and get predicted values
lm_fit <- lm(ATT8SCR ~ PTFSM6CLA1A, data = btn_sub)
btn_sub <- btn_sub %>%
  mutate(predicted = predict(lm_fit),
         residual = ATT8SCR - predicted)

# Create annotation text
slope <- round(coef(lm_fit)[2], 2)
intercept <- round(coef(lm_fit)[1], 2)
annotation_text <- paste0("y = ", intercept, " + ", slope, "x")

# Assign colors to schools
school_levels <- unique(btn_sub$SCHNAME.x)
school_colors <- setNames(
  rep(custom_colors, length.out = length(school_levels)),
  school_levels
)

# Plot with residual lines and custom colors
ggplot(btn_sub, aes(x = PTFSM6CLA1A, y = ATT8SCR, color = SCHNAME.x)) +
  geom_point(size = 3, alpha = 0.9) +
  labs(
    title = "Brighton and Hove Schools - Attainment 8 vs % Disadvantaged Students, 2022-23",
    x = "% Disadvantaged Students",
    y = "Average Attainment 8 Score",
    color = "School"
  ) +
  scale_color_manual(values = school_colors) +
  theme_minimal() +
  theme(
    legend.position = c(1, 1),           # top-right inside plot
    legend.justification = c(1, 1)
  ) 

```

-   **A regression model is nothing more than a description of a scatter plot**
-   Dependent variable = $Y$-axis 
-   Independent variable = $X$-axis

## Linear Regression - Line of Best-fit

```{r}
#| out-width: "60%"
#| fig-align: "center"
#| 
## get LEA Code from here: https://get-information-schools.service.gov.uk/Guidance/LaNameCodes

# Filter data
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Fit linear model
lm_fit <- lm(ATT8SCR ~ PTFSM6CLA1A, data = btn_sub)
slope <- round(coef(lm_fit)[2], 2)
intercept <- round(coef(lm_fit)[1], 2)

# Create annotation text
annotation_text <- paste0("y = ", intercept, " + ", slope, "x")

# Plot with annotation
ggplot(btn_sub) +
  geom_point(aes(x = PTFSM6CLA1A, y = ATT8SCR)) +
  geom_smooth(aes(x = PTFSM6CLA1A, y = ATT8SCR), method = "lm", se = FALSE, color = "#8F5289") +
  labs(title = "Brighton and Hove Schools - Attainment 8 vs % Disadvantaged Students, 2022-23",
       x = "% Disadvantaged Students",
       y = "Average Attainment 8 Score") +
  theme_minimal()
```

-   The linear regression model is the straight line of best-fit 
-   A linear model function `lm()` (in `R`) uses a method called ***Ordinary Least Squares (OLS)*** to find the line of best-fit.
-   The best line minimises the squared (so that negatives and positives don't candel) vertical distances between the line and the points - hence OLS

## Linear Regression - Residuals / Error

```{r}
#| out-width: "60%"
#| fig-align: "center"

# Filter data (assuming england_filtered is in your environment)
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Fit linear model
lm_fit <- lm(ATT8SCR ~ PTFSM6CLA1A, data = btn_sub)

# Get the R-squared value from the model summary
r2_value <- summary(lm_fit)$r.squared

# Create the annotation text with the R-squared value, rounded to 2 decimal places
annotation_text <- paste0("R² = ", round(r2_value, 2))

# Plot with residual lines and the new annotation
ggplot(btn_sub, aes(x = PTFSM6CLA1A, y = ATT8SCR)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "#8F5289") +
  geom_segment(aes(xend = PTFSM6CLA1A, yend = predict(lm_fit)),
               linetype = "dotted", color = "grey50") +
  # Use the new R-squared annotation
  annotate("text", 
           x = max(btn_sub$PTFSM6CLA1A, na.rm = TRUE), 
           y = min(btn_sub$ATT8SCR, na.rm = TRUE), 
           label = annotation_text, 
           hjust = 1, vjust = -10, size = 4, color = "#4E3C56") +
  labs(title = "Brighton and Hove Schools - Attainment 8 vs % Disadvantaged Students, 2022-23",
       x = "% Disadvantaged Students",
       y = "Average Attainment 8 Score") +
  theme_minimal()
```

-   The vertical distances between the points and the line of best fit are called the **residuals** - sometimes also referred to as the **errors** or $\epsilon$
-   The closer the points are to the line, the better the fit of the model

## Linear Regression - R-Squared

```{r}
#| out-width: "60%"
#| fig-align: "center"

# Filter data (assuming england_filtered is in your environment)
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Fit linear model
lm_fit <- lm(ATT8SCR ~ PTFSM6CLA1A, data = btn_sub)

# Get the R-squared value from the model summary
r2_value <- summary(lm_fit)$r.squared

# Create the annotation text with the R-squared value, rounded to 2 decimal places
annotation_text <- paste0("R² = ", round(r2_value, 2))

# Plot with residual lines and the new annotation
ggplot(btn_sub, aes(x = PTFSM6CLA1A, y = ATT8SCR)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "#8F5289") +
  geom_segment(aes(xend = PTFSM6CLA1A, yend = predict(lm_fit)),
               linetype = "dotted", color = "grey50") +
  # Use the new R-squared annotation
  annotate("text", 
           x = max(btn_sub$PTFSM6CLA1A, na.rm = TRUE), 
           y = min(btn_sub$ATT8SCR, na.rm = TRUE), 
           label = annotation_text, 
           hjust = 1, vjust = -10, size = 4, color = "#4E3C56") +
  labs(title = "Brighton and Hove Schools - Attainment 8 vs % Disadvantaged Students, 2022-23",
       x = "% Disadvantaged Students",
       y = "Average Attainment 8 Score") +
  theme_minimal()
```

-   The fit of the model is represented by the $R^2$ value and is calculated from the residuals
-   It describes how much of the variation in $Y$ (Attainment 8 score) is explained by the variation in $X$ (% Disadvantaged Students) - here 69%
-   The closer to 1, the better the fit of the model


## Linear Regression - Slope and Intercept

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: center
#| out-width: 60%

# Filter data
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Fit linear model and get predicted values
lm_fit <- lm(ATT8SCR ~ PTFSM6CLA1A, data = btn_sub)
btn_sub <- btn_sub %>%
  mutate(predicted = predict(lm_fit),
         residual = ATT8SCR - predicted)


# Create annotation text
slope <- round(coef(lm_fit)[2], 2)
intercept <- round(coef(lm_fit)[1], 2)
annotation_text <- paste0("y = ", intercept, " + ", slope, "x")

ggplot(btn_sub, aes(x = PTFSM6CLA1A, y = ATT8SCR)) +
  geom_point() +
  geom_abline(intercept = coef(lm_fit)[1], slope = coef(lm_fit)[2], color = "#8F5289") +
  geom_segment(aes(xend = PTFSM6CLA1A, yend = predicted),
               linetype = "dotted", color = "grey50") +
  annotate("text", x = max(btn_sub$PTFSM6CLA1A, na.rm = TRUE), 
           y = min(btn_sub$ATT8SCR, na.rm = TRUE), 
           label = annotation_text, hjust = 1, vjust = -15, size = 4, color = "#4E3C56") +
  labs(title = "Brighton and Hove Schools - Attainment 8 vs % Disadvantaged Students, 2022-23",
       x = "% Disadvantaged Students",
       y = "Average Attainment 8 Score") +
  xlim(0, max(50)) +
  ylim(min(30), 65) +
  theme_minimal()

```

-   The regression line itself can be described by an equation with two parameters / coefficients:
    -   The **intercept** - $\beta_0$ - which is the value of $Y$ when $X = 0$
    -   The **slope** - $\beta_1$ - which the change in the value of $Y$ for a 1 unit change in $X$

## Linear Regression - Model Estimates

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: center
#| out-width: 60%

# Filter data
btn_sub <- england_filtered %>%
  filter(LEA == 846) %>% 
  select(URN, SCHNAME.x, LEA, ATT8SCR, PTFSM6CLA1A)

# Fit linear model and get predicted values
lm_fit <- lm(ATT8SCR ~ PTFSM6CLA1A, data = btn_sub)
btn_sub <- btn_sub %>%
  mutate(predicted = predict(lm_fit),
         residual = ATT8SCR - predicted)


# Create annotation text
slope <- round(coef(lm_fit)[2], 2)
intercept <- round(coef(lm_fit)[1], 2)
annotation_text <- paste0("y = ", intercept, " + ", slope, "x")

ggplot(btn_sub, aes(x = PTFSM6CLA1A, y = ATT8SCR)) +
  geom_point() +
  geom_abline(intercept = coef(lm_fit)[1], slope = coef(lm_fit)[2], color = "#8F5289") +
  geom_segment(aes(xend = PTFSM6CLA1A, yend = predicted),
               linetype = "dotted", color = "grey50") +
  annotate("text", x = max(btn_sub$PTFSM6CLA1A, na.rm = TRUE), 
           y = min(btn_sub$ATT8SCR, na.rm = TRUE), 
           label = annotation_text, hjust = 1, vjust = -15, size = 4, color = "#4E3C56") +
  labs(title = "Brighton and Hove Schools - Attainment 8 vs % Disadvantaged Students, 2022-23",
       x = "% Disadvantaged Students",
       y = "Average Attainment 8 Score") +
  xlim(0, max(50)) +
  ylim(min(30), 65) +
  theme_minimal()

```
$$Y = \beta_0 + \beta_1X_1 + \epsilon$$
$$\hat{Y} = 62.35 + (-0.63 * X) + \epsilon$$
$$49.75 = 62.35 + (-0.63 * 20) + 0$$


## Linear Regression - The Statistical Model

```{r}
#| out-width: "40%"
#| out-height: "50%"
#| fig-align: "center"
summary(lm_fit)
```
-   Scatter plots are an excellent intuitive way to understand the relationship between two continuous variables
-   Statistical software describes key plot features + other useful info

## Linear Regression - Running the Model

![](images/the_Call.png)

-   This is the code representation of the model equation we saw earlier:
    -   `lm()` is the function that fits a linear model
    -   `ATT8SCR` (Attainment 8 Score) is the dependent variable $Y$
    -   `~` means "is modelled by"
    -   `PTFSM6CLA1A` (% Disadvantaged Students) is the independent variable $X$
    -   `data = bnt_sub` is the dataset we are using which contains the variables
    

## Linear Regression - Residuals and Error

![](images/the_resids.png)
![](images/the_error.png)

-   The residual errors range from -8.3 (Longhill) to + 4.7 (Varndean)
-   The residual standard error of 4.087 means that, on average, the model's predictions for a school's Attainment 8 score are off by about 4.1 points
-   Residual Standard Error (RSE) and $R^2$ are inversely related and both derived from the sum of the squared residual error (SSE)
-   A smaller RSE and larger $R^2$ both mean a more precise model
-   The F-Statistic is a ratio of the amount of variance explained by the model to the amount of variance not explained by the model - bigger the better

## Linear Regression - Degrees of Freedom
![](images/the_error.png)


-   DF relates to the **Degrees of Freedom** in the model and is *very* important for understanding how reliable your $R^2$ value might be
    -   The first number (1) relates to the number of variables
    -   The second number (8) relates to the number of observations / cases in the dataset, minus the number of parameters 
    -   In our example we have 10 observations and 2 parameters (intercept and slope) so 10 - 2 = 8 degrees of freedom
    
## Linear Regression - Degrees of Freedom
    
-   As a general rule: more degrees of freedom = more reliable model
-   A model with many parameters vs observations will bend to fit those observations and not be a good generalisation - this is called ***overfitting***.
-   A model with little freedom might *appear* to have a high $R^2$
    -   but it is likely to perform poorly on new, unseen data 
    -   **it has captured the characteristics of your specific dataset rather than the underlying truth**
    
## Linear Regression - Degrees of Freedom

-   **How many Degrees of Freedom are required for a reliable model?**
-   No single, universally agreed-upon number - aim to maintain a healthy ratio of observations to the number of parameters
-   A common rule of thumb is the 10:1 ratio - **10 observations for every one parameter** - although this is a rough guide. If in doubt, even up to 20:1 to be safe
-   In our example, we have 10 observations and 2 parameters, so 5:1 ratio - potentially an unreliable model

## Linear Regression - Interpreting Coefficients 1
![](images/the_coefs.png)

-   The Estimate ($\beta$) 
    -   intercept - estimated ATT8SCR when PTFSM6CLA1A is zero
    -   effect of a one-unit change in the PTFSM6CLA1A on ATT8SCR - therefore sensitive to the units of the independent variable and not directly comparable across different variables if measured on different scales

## Linear Regression - Interpreting Coefficients 2
![](images/the_coefs.png)

-   The Standard Error (SE) - measure of the uncertainty or precision of the estimate
    -   Large SE relative to the Estimate = estimate unreliable / uncertain
    -   SE of 0.15 for the estimate of -0.63 for PTFSM6CLA1A means the change in the value of Attainment 8 for a 1% change in disadvantaged students could vary between -0.48 and -0.78

## Linear Regression - Interpreting Coefficients 3
![](images/the_coefs.png)

-   The t-value - ratio of the Estimate to the SE
    -   a large standard error will make the t-value small (close to zero)
    -   t-values can be thought of as a standardised coefficient - very useful for comparing the relative importance of different predictors in the model
    -   The larger the t-value, the more significant the predictor is in explaining the variation in the dependent variable (more importance in your model)
    
## Linear Regression - Interpreting Coefficients 4
![](images/the_coefs.png)

-   The p-value - probability of observing a t-value as extreme as the one calculated if there were no relationship between the independent and the dependent variable
-   A small p-value (typically < 0.05) indicates that the predictor is statistically significant in explaining the variation in the dependent variable
-   The Signif. codes (like *** and **) are just a quick visual guide to this p-value, showing you at a glance which variables are significant.


## Regression Fundamentals {transition="convex-in none-out" transition-speed="fast"}

-   Regression is a statistical method used to understand the relationship between one or more independent variables (predictors) and a dependent variable (outcome)
-   Even more simply the dependent variable is the thing you want to predict, and the independent variables are the things you think might influence that prediction
-   The simplest form is **linear regression**, which assumes a linear relationship between the independent and dependent variables
-   In a simple linear regression the dependent variable is measured on a continuous scale - in our case this might the average Attainment 8 scores for all schools in England and Wales

## Regression Maths

-   The general form of a linear regression model is:

    $$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_nX_n + \epsilon$$

    where:

    -   $Y$ is the dependent variable
    -   $X_1, X_2, ..., X_n$ are the independent variables
    -   $\beta_0$ is the intercept (constant term)
    -   $\beta_1, \beta_2, ..., \beta_n$ are the coefficients for each independent variable
    -   $\epsilon$ is the error term (residuals)